# Visual Strategy

> How images work in Fantazy—from static avatars to dynamic story visualization.

## The Spectrum of Visual Interaction

From simplest to most complex:

### Level 0: Static Avatar Only
```
┌─────────────────────┐
│  [Character Image]  │  ← Same image always
│                     │
│  Character: Hey!    │
│  You: Hi there      │
│  Character: ...     │
└─────────────────────┘
```
- Single profile image per character
- Shown in chat header
- No dynamic generation

**Pros:** Simple, cheap, consistent, fast
**Cons:** Less immersive, no story visualization

---

### Level 1: Expression Variants
```
┌─────────────────────┐
│  [Happy/Sad/etc]    │  ← 5-10 pre-made variants
│                     │
│  Character: I'm so  │
│  happy for you!     │
└─────────────────────┘
```
- Pre-made expression set per character
- LLM outputs emotion tag, frontend shows matching image
- Like visual novel sprites

**Pros:** More expressive, still fast, no generation cost
**Cons:** Limited to pre-made set, upfront art cost

---

### Level 2: Scene Images (Story Moments)
```
┌─────────────────────────────────────┐
│  Character: Let's grab coffee       │
│                                     │
│  ┌─────────────────────────────┐   │
│  │  [Generated: Two people at  │   │  ← Generated at key moments
│  │   coffee shop, warm light]  │   │
│  └─────────────────────────────┘   │
│                                     │
│  Character: This is nice...        │
└─────────────────────────────────────┘
```
- Generate images at specific story moments
- Inline in chat, like picture messages
- Triggered by story beats, not every message

**Pros:** Immersive, story-like, memorable moments
**Cons:** Generation latency, cost, consistency challenges

---

### Level 3: Continuous Visual Presence (X.ai Grok "Ani" style)
```
┌─────────────────────────────────────┐
│  ┌─────────────────────────────┐   │
│  │  [Live avatar that moves,   │   │  ← Real-time animated presence
│  │   reacts, emotes]           │   │
│  └─────────────────────────────┘   │
│                                     │
│  [Chat messages below]              │
└─────────────────────────────────────┘
```
- Animated avatar with real-time reactions
- Lip sync, expressions, gestures
- Video/animation generation or Live2D

**Pros:** Most "alive" feeling, high engagement
**Cons:** Very complex, expensive, technical challenge

---

## Recommended Approach

### Phase 1: Level 0 + 1 Hybrid (MVP)
**Start with static avatars, prepare for expression variants**

1. Each character gets 1 high-quality base image
2. Design image to work at multiple sizes (header, card, chat)
3. Prepare pipeline for adding expression variants later
4. Focus engineering on conversation quality

**Why:**
- Images aren't the core value prop—memory is
- Validate conversation stickiness first
- Reduce complexity for faster iteration

### Phase 2: Level 2 (Story Images)
**Add generated images at key moments**

Trigger points:
- First message in a new relationship stage
- User explicitly requests ("what does that look like?")
- Special scenes (first date, celebration)
- Milestone moments in relationship

Image prompts would be:
- Generated by LLM based on conversation context
- Include character description for consistency
- Include scene description from conversation

### Phase 3: Evaluate Level 3
**Only if data shows visual presence drives retention**

This is a significant technical investment. Only pursue if:
- Phase 1-2 show strong retention
- User feedback explicitly requests this
- Cost model supports it

---

## Image Generation Options

### For Phase 2 (Story Images)

#### Gemini Imagen (Recommended to evaluate)
- **Pros:** Native multimodal, cheap, fast, same API as text
- **Cons:** Quality TBD, anime style uncertain, Google restrictions

#### DALL-E 3
- **Pros:** High quality, good at following prompts
- **Cons:** Expensive (~$0.04-0.12/image), separate API

#### Stable Diffusion (API services)
- **Pros:** Cheap, flexible, can fine-tune for character consistency
- **Cons:** Quality varies, anime models exist but need selection
- Services: Replicate, RunPod, StabilityAI API

#### Midjourney (via unofficial APIs)
- **Pros:** Excellent quality, good at anime style
- **Cons:** No official API, TOS concerns, queue-based

### Character Consistency Challenge

Major problem: Generated images need to show the SAME character each time.

Solutions:
1. **Detailed prompt engineering** - Include character description in every prompt
2. **Fine-tuned model** - Train LoRA/DreamBooth on character
3. **Face swap post-processing** - Generate scene, swap in consistent face
4. **Reference image** - Use image-to-image with character base

---

## Cost Analysis

### Scenario: 1000 Daily Active Users

#### Static Only (Level 0-1)
- Image cost: $0 (pre-made)
- Storage: Minimal (S3/Cloudflare)
- **Monthly: ~$10-20 for hosting**

#### Story Images (Level 2, moderate)
Assuming 2 images per user per day:
- 2000 images/day × 30 days = 60,000 images/month

| Provider | Cost/Image | Monthly Cost |
|----------|------------|--------------|
| DALL-E 3 | $0.08 | $4,800 |
| Stable Diffusion API | $0.01 | $600 |
| Gemini Imagen | ~$0.01 | $600 |
| Self-hosted SD | ~$0.002 | $120 |

#### Story Images (Level 2, heavy)
Assuming 5 images per user per day:
- 5000 images/day × 30 days = 150,000 images/month

| Provider | Cost/Image | Monthly Cost |
|----------|------------|--------------|
| DALL-E 3 | $0.08 | $12,000 |
| Stable Diffusion API | $0.01 | $1,500 |
| Gemini Imagen | ~$0.01 | $1,500 |
| Self-hosted SD | ~$0.002 | $300 |

**Takeaway:** Self-hosted Stable Diffusion or Gemini Imagen for cost-effectiveness at scale.

---

## Character Image Requirements

### Base Image (Level 0)
For each character, we need:
- **Full portrait** - Upper body, expressive face
- **Square crop** - For avatars/thumbnails
- **Style:** Anime/webtoon inspired, warm, approachable
- **Resolution:** 1024x1024 minimum, scalable

### Expression Set (Level 1)
If/when we add expressions:
- Happy/delighted
- Thinking/contemplative
- Embarrassed/blushing
- Concerned/worried
- Playful/teasing
- Neutral/default

### Scene Generation Prompts (Level 2)
Template structure:
```
Setting: [coffee shop / apartment / office / etc]
Time: [morning / afternoon / evening / night]
Mood: [warm / cozy / romantic / playful]
Character: [detailed description of character appearance]
Scene: [what's happening - generated from conversation]
Style: anime, soft lighting, warm colors, slice-of-life
```

---

## Implementation Plan

### Immediate (Week 1)
1. Ensure current character images work well
2. Verify image display in chat UI
3. Document character visual descriptions for future generation

### Short-term (Week 2-4)
1. Test Gemini Imagen quality/speed
2. Test Stable Diffusion APIs (Replicate, etc.)
3. Define trigger points for image generation
4. Build image generation abstraction in API

### Medium-term (Month 2+)
1. Implement scene image generation
2. A/B test image vs no-image retention
3. Iterate on prompt engineering for consistency
4. Consider expression variants if data supports

---

## Open Questions

1. **Do users actually want images?** Or is conversation enough?
2. **How important is character consistency?** Can we tolerate variation?
3. **What triggers feel right?** Every N messages? Story beats? User request?
4. **Anime quality:** Which generators best match our style?
5. **Moderation:** How do we handle generated image content?
6. **Caching:** Can we cache/reuse scene images?

---

## Research Tasks

- [ ] Test Gemini Imagen with anime-style prompts
- [ ] Test Stable Diffusion XL anime models (anything-v5, counterfeit, etc.)
- [ ] Benchmark latency for image generation options
- [ ] Survey competitors' visual approaches
- [ ] User research: What do users expect/want visually?
